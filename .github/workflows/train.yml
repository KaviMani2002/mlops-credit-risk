name: Train Multi Model with DVC

on:
  workflow_dispatch:
  push:
    paths:
      - 'src/**.py'
      - '.github/workflows/train.yml'

jobs:
  train-model:
    runs-on: ubuntu-latest

    env:
      MLFLOW_TRACKING_URI: http://20.106.177.129:5000
      AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}
      AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}
      # or use the below line if you're using connection string instead
      # AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
      GITHUB_ACTIONS: true  # lets your script detect it's running in CI

    steps:
      - name: üì• Checkout repo
        uses: actions/checkout@v3

      - name: üêç Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: üì¶ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install 'dvc[azure]'

      - name: ‚öôÔ∏è Configure DVC Azure Remote
        run: |
          dvc remote add -d azureremote azure://dvcdata
          dvc remote modify azureremote connection_string "${{ secrets.AZURE_DVC_CONNECTION }}"

      - name: ‚¨áÔ∏è Pull data from Azure DVC remote
        run: dvc pull

      - name: üìÇ Run data ingestion
        run: python src/data_ingestion.py

      - name: üßπ Run data cleaning
        run: python src/data_cleaning.py

      - name: üèóÔ∏è Run feature engineering
        run: python src/feature_engineering.py

      - name: üöÄ Train models and log to MLflow
        run: python src/train_multi_model.py

