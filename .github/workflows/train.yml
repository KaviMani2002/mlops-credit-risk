name: Train Multi Model with DVC
 
on:
  workflow_dispatch:
  push:
    paths:
      - 'src/**.py'
      - '.github/workflows/train.yml'
 
jobs:
  train-model:
    runs-on: self-hosted  # ‚úÖ Use self-hosted runner
 
    env:
      MLFLOW_TRACKING_URI: http://20.106.177.129:5000
      AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}
      AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}
      # or use the below line if you're using connection string instead
      # AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
      GITHUB_ACTIONS: true
 
    steps:
      - name: üì• Checkout repo
        uses: actions/checkout@v3
 
      - name: üêç Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
 
      - name: üì¶ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install 'dvc[azure]'
 
      - name: ‚öôÔ∏è Configure DVC Azure Remote
        run: |
          dvc remote add -d azureremote azure://dvcdata
          dvc remote modify azureremote connection_string "${{ secrets.AZURE_DVC_CONNECTION }}"
 
      - name: ‚¨áÔ∏è Pull data from Azure DVC remote
        run: dvc pull
 
      # ---------- DATA INGESTION ----------
      - name: üîç Before Data Ingestion - Show working directory and files
        run: |
          echo "PWD before ingestion:"
          pwd
          echo "Files before ingestion:"
          ls -R
 
      - name: üìÇ Run data ingestion
        run: python src/data_ingestion.py
 
      - name: üîç After Data Ingestion - Show working directory and files
        run: |
          echo "PWD after ingestion:"
          pwd
          echo "Files after ingestion:"
          ls -R
 
      # ---------- DATA CLEANING ----------
      - name: üîç Before Data Cleaning - Show working directory and files
        run: |
          echo "PWD before cleaning:"
          pwd
          echo "Files before cleaning:"
          ls -R
 
      - name: üßπ Run data cleaning
        run: python src/data_cleaning.py
 
      - name: üîç After Data Cleaning - Show working directory and files
        run: |
          echo "PWD after cleaning:"
          pwd
          echo "Files after cleaning:"
          ls -R
 
      # ---------- FEATURE ENGINEERING ----------
      - name: üîç Before Feature Engineering - Show working directory and files
        run: |
          echo "PWD before feature engineering:"
          pwd
          echo "Files before feature engineering:"
          ls -R
 
      - name: üèóÔ∏è Run feature engineering
        run: python src/feature_engineering.py
 
      - name: üîç After Feature Engineering - Show working directory and files
        run: |
          echo "PWD after feature engineering:"
          pwd
          echo "Files after feature engineering:"
          ls -R
 
      # ---------- MODEL TRAINING ----------
      - name: üöÄ Train models and log to MLflow
        run: python src/train_multi_model.py
      - name: üöÄ Promote Models to Staging stage
        run: python src/promote_best_models.py
 
      # ---------- CLEANUP STEP ----------
      - name: üßπ Cleanup runner workspace
        if: always()
        run: |
          echo "Cleaning up runner workspace..."
          sudo rm -rf "$RUNNER_WORKSPACE"/*
