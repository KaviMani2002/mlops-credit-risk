name: Train Multi Model with DVC

on:
  workflow_dispatch:
  push:
    paths:
      - 'src/**.py'
      - '.github/workflows/train.yml'

jobs:
  train-model:
    runs-on: self-hosted  # pin to your runner

    env:
      MLFLOW_TRACKING_URI: http://20.106.177.129:5000
      AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}
      AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}
      GITHUB_ACTIONS: true

    steps:
      - name: ğŸ“¥ Checkout repo
        uses: actions/checkout@v3

      - name: ğŸ–¥ï¸ Debug runner environment
        run: |
          echo "Runner OS: ${{ runner.os }}"
          echo "Architecture: ${{ runner.arch }}"
          python3 --version
          pip3 --version
          df -h
          free -m
      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: ğŸ“¦ Install dependencies
        run: |
          python3 -m pip install --upgrade pip
          pip3 install -r requirements.txt
          pip3 install 'dvc[azure]'
      - name: âš™ï¸ Configure DVC Azure Remote
        run: |
          dvc remote list | grep azureremote || dvc remote add -d azureremote azure://dvcdata
          dvc remote modify azureremote connection_string "${{ secrets.AZURE_DVC_CONNECTION }}"
      - name: â¬‡ï¸ Pull data from Azure DVC remote
        run: dvc pull

      - name: ğŸ” Verify pulled data integrity
        run: |
          dvc status -c
          dvc doctor
          ls -lh data/ || true
          ls -lh *.dvc || true
          dvc list .
      - name: ğŸ“‚ Run data ingestion
        run: python3 src/data_ingestion.py

      - name: ğŸ§¹ Run data cleaning
        run: python3 src/data_cleaning.py

      - name: ğŸ—ï¸ Run feature engineering
        run: python3 src/feature_engineering.py

      - name: ğŸš€ Train models and log to MLflow
        run: python3 src/train_multi_model.py

      - name: ğŸš€ Promote Models to Staging stage
        run: python3 src/promote_best_models.py
